{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39a806c-02a3-4a2d-8c51-f1ab1ea79d2e",
   "metadata": {},
   "source": [
    "# LLM Reasoning\n",
    "\n",
    "This notebook compares how LLMs (mainly Llama 3 and 3.1, but other LLMs can be added easily) from different Generative AI providers perform on three recent examples that show issues with LLM reasoning:\n",
    "\n",
    "* [The Reversal Curse](https://github.com/lukasberglund/reversal_curse) shows that LLMs trained on \"A is B\" fail to learn \"B is A\".\n",
    "* [How many r's in the word strawberry?](https://x.com/karpathy/status/1816637781659254908) shows \"the weirdness of LLM Tokenization\".  \n",
    "* [Which number is bigger, 9.11 or 9.9?](https://x.com/DrJimFan/status/1816521330298356181) shows that \"LLMs are alien beasts.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e413bd-983c-42a0-9580-96fedc7b1275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTHROPIC_API_KEY=\"\"\n",
      "FIREWORKS_API_KEY=\"\"\n",
      "GROQ_API_KEY=\"\"\n",
      "MISTRAL_API_KEY=\"\"\n",
      "OPENAI_API_KEY=\"\"\n",
      "OLLAMA_API_URL=\"http://localhost:11434\"\n",
      "REPLICATE_API_KEY=\"\"\n",
      "TOGETHER_API_KEY=\"\"\n",
      "OCTO_API_KEY=\"\"\n",
      "AWS_ACCESS_KEY_ID=\"\"\n",
      "AWS_SECRET_ACCESS_KEY=\"\""
     ]
    }
   ],
   "source": [
    "!cat ../.env.sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d843e36-7de6-4726-8a39-c5dcd3c7cc11",
   "metadata": {},
   "source": [
    "Make sure your ~/.env file (copied from the .env.sample file above) has the API keys of the LLM providers to compare set before running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c966895-1a63-4922-80b7-5a20e47f29de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../aimodels')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e093e4-31b6-4df0-9121-d1dceaa39cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install boto3\n",
    "#!pip install fireworks-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5c5be-1085-4252-9d5e-80b50961484b",
   "metadata": {},
   "source": [
    "## Specify LLMs to Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c3d5ef-b1c9-48dd-9b89-30799fd4b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aimodels as ai\n",
    "\n",
    "client = ai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886a904f-fef0-4f25-b3ed-41085bf0f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = [\"aws:meta.llama3-8b-instruct-v1:0\",\n",
    "        \"groq:llama3-8b-8192\",\n",
    "        \"fireworks:accounts/fireworks/models/llama-v3-8b-instruct\",\n",
    "        \"octo:meta-llama-3-8b-instruct\",\n",
    "        \"together:meta-llama/Llama-3-8b-chat-hf\",\n",
    "        \"openai:gpt-3.5-turbo\",\n",
    "        \"replicate:meta/meta-llama-3-8b-instruct\",\n",
    "\n",
    "        \"aws:meta.llama3-1-8b-instruct-v1:0\",\n",
    "        \"groq:llama-3.1-8b-instant\",\n",
    "        \"fireworks:accounts/fireworks/models/llama-v3p1-8b-instruct\",\n",
    "        \"together:meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "        \"octo:meta-llama-3.1-8b-instruct\",\n",
    "        \n",
    "       ]\n",
    "\n",
    "def compare_llm(messages):\n",
    "    for llm in llms:\n",
    "        response = client.chat.completions.create(model=llm, messages=messages)\n",
    "        print(f\"{llm} - {response.choices[0].message.content.strip()}\\n==========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3e8aa2-4ff4-485b-93d9-4a6f22d62e67",
   "metadata": {},
   "source": [
    "## The Reversal Curse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c4a8ef-e23b-4d4a-8561-3e5a2a866bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who is Tom Cruise's mother?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e901285-6ca7-4e82-8829-12b24fb9ff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws:meta.llama3-8b-instruct-v1:0 - Tom Cruise's mother is Mary Lee South (née Pfeiffer).\n",
      "==========\n",
      "groq:llama3-8b-8192 - Tom Cruise's mother is Mary Lee South (née Pfeiffer). She was a special education teacher and a homemaker.\n",
      "==========\n",
      "fireworks:accounts/fireworks/models/llama-v3-8b-instruct - Tom Cruise's mother is Mary Lee South (née Pfeiffer).\n",
      "==========\n",
      "octo:meta-llama-3-8b-instruct - Tom Cruise's mother is Mary Lee South (née Pfeiffer).\n",
      "==========\n",
      "together:meta-llama/Llama-3-8b-chat-hf - Tom Cruise's mother is Mary Lee South (née Pfeiffer).\n",
      "==========\n",
      "openai:gpt-3.5-turbo - Tom Cruise's mother is Mary Lee Pfeiffer.\n",
      "==========\n",
      "replicate:meta/meta-llama-3-8b-instruct - Tom Cruise's mother is Mary Lee South (née Pfeiffer).\n",
      "==========\n",
      "aws:meta.llama3-1-8b-instruct-v1:0 - Tom Cruise's mother is Mary Lee Pfeiffer.\n",
      "==========\n",
      "groq:llama-3.1-8b-instant - Tom Cruise's mother is Mary Lee Pfeiffer.\n",
      "==========\n",
      "fireworks:accounts/fireworks/models/llama-v3p1-8b-instruct - Tom Cruise's mother is Mary Lee Pfeiffer.\n",
      "==========\n",
      "together:meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo - Tom Cruise's mother is Mary Lee Pfeiffer.\n",
      "==========\n",
      "octo:meta-llama-3.1-8b-instruct - Tom Cruise's mother is Mary Lee Pfeiffer.\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "compare_llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "399f6cca-7f34-4a91-aab0-070560640033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws:meta.llama3-8b-instruct-v1:0 - I apologize, but I couldn't find any information on a person named Mary Lee Pfeiffer or her son. It's possible that this is a private individual and not a public figure, or that the name is not well-known. Can you provide more context or details about who Mary Lee Pfeiffer is or why you are looking for information about her son?\n",
      "==========\n",
      "groq:llama3-8b-8192 - I apologize, but I couldn't find any information on a person named Mary Lee Pfeiffer or her son. It's possible that this is a private or personal matter, or that the person is not a public figure. Can you provide more context or clarify who Mary Lee Pfeiffer is?\n",
      "==========\n",
      "fireworks:accounts/fireworks/models/llama-v3-8b-instruct - Mary Lee Pfeiffer is a well-known American artist, and her son is none other than the famous artist and sculptor, John Pfeiffer!\n",
      "==========\n",
      "octo:meta-llama-3-8b-instruct - I apologize, but I couldn't find any information on a person named Mary Lee Pfeiffer or her son. It's possible that this is a private or personal matter, or that the person is not a public figure. Can you provide more context or clarify who Mary Lee Pfeiffer is?\n",
      "==========\n",
      "together:meta-llama/Llama-3-8b-chat-hf - I apologize, but I couldn't find any information on a person named Mary Lee Pfeiffer or her son. It's possible that this is a private or personal matter, or that the person is not a public figure. Can you provide more context or clarify who Mary Lee Pfeiffer is?\n",
      "==========\n",
      "openai:gpt-3.5-turbo - Mary Lee Pfeiffer's son is actor and filmmaker Joaquin Phoenix.\n",
      "==========\n",
      "replicate:meta/meta-llama-3-8b-instruct - According to my knowledge, Mary Lee Pfeiffer's son is John Pfeiffer.\n",
      "==========\n",
      "aws:meta.llama3-1-8b-instruct-v1:0 - I don't have information on Mary Lee Pfeiffer's son. Is there something else I can help you with?\n",
      "==========\n",
      "groq:llama-3.1-8b-instant - I don't have information on Mary Lee Pfeiffer's son. Is there something else I can help you with?\n",
      "==========\n",
      "fireworks:accounts/fireworks/models/llama-v3p1-8b-instruct - I don't have information on Mary Lee Pfeiffer's son.\n",
      "==========\n",
      "together:meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo - I am unable to verify who Mary Lee Pfeiffer's son is.\n",
      "==========\n",
      "octo:meta-llama-3.1-8b-instruct - I don't have information on Mary Lee Pfeiffer's son. Is there something else I can help you with?\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who is Mary Lee Pfeiffer's son?\"},\n",
    "]\n",
    "compare_llm(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8e0fb-17f0-4781-bf6a-c23ac86922ad",
   "metadata": {},
   "source": [
    "## How many r's in the word strawberry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e537871e-68b6-44c3-886a-d3ebe7a692c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws:meta.llama3-8b-instruct-v1:0 - There are 2 R's in the word \"strawberry\".\n",
      "==========\n",
      "groq:llama3-8b-8192 - There are 2 R's in the word \"strawberry\".\n",
      "==========\n",
      "fireworks:accounts/fireworks/models/llama-v3-8b-instruct - There are 2 R's in the word \"strawberry\".\n",
      "==========\n",
      "octo:meta-llama-3-8b-instruct - There are 2 R's in the word \"strawberry\".\n",
      "==========\n",
      "together:meta-llama/Llama-3-8b-chat-hf - There are 2 R's in the word \"strawberry\".\n",
      "==========\n",
      "openai:gpt-3.5-turbo - There are three r's in the word \"strawberry.\"\n",
      "==========\n",
      "replicate:meta/meta-llama-3-8b-instruct - Let me count them for you!\n",
      "\n",
      "There are 2 R's in the word \"strawberry\".\n",
      "==========\n",
      "aws:meta.llama3-1-8b-instruct-v1:0 - There are 3 r's in the word \"strawberry\".\n",
      "==========\n",
      "groq:llama-3.1-8b-instant - There are 3 r's in the word \"strawberry\".\n",
      "==========\n",
      "fireworks:accounts/fireworks/models/llama-v3p1-8b-instruct - There are 2 r's in the word strawberry.\n",
      "==========\n",
      "together:meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo - There are 2 r's in the word strawberry.\n",
      "==========\n",
      "octo:meta-llama-3.1-8b-instruct - There are 3 r's in the word \"strawberry\".\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"How many r's in the word strawberry?\"},\n",
    "]\n",
    "compare_llm(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3fb5f-a173-4a33-b843-65df6d1086f9",
   "metadata": {},
   "source": [
    "## Which number is bigger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efdf2fd6-f63a-4f9b-af15-1df25590e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Which number is bigger, 9.11 or 9.9?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaa14ed1-c83b-4c8f-bb14-d318bf0c9a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws:meta.llama3-8b-instruct-v1:0 - 9.9 is bigger than 9.11.\n",
      "==========\n",
      "groq:llama3-8b-8192 - 9.11 is bigger than 9.9.\n",
      "==========\n",
      "fireworks:accounts/fireworks/models/llama-v3-8b-instruct - 9.9 is bigger than 9.11.\n",
      "==========\n",
      "octo:meta-llama-3-8b-instruct - 9.11 is bigger than 9.9.\n",
      "==========\n",
      "together:meta-llama/Llama-3-8b-chat-hf - 9.11 is bigger than 9.9.\n",
      "==========\n",
      "openai:gpt-3.5-turbo - 9.9\n",
      "==========\n",
      "replicate:meta/meta-llama-3-8b-instruct - Let me help you with that!\n",
      "\n",
      "9.11 is bigger than 9.9.\n",
      "==========\n",
      "aws:meta.llama3-1-8b-instruct-v1:0 - The number 9.11 is bigger than 9.9.\n",
      "==========\n",
      "groq:llama-3.1-8b-instant - 9.9 is bigger than 9.11.\n",
      "==========\n",
      "fireworks:accounts/fireworks/models/llama-v3p1-8b-instruct - 9.9 is bigger than 9.11.\n",
      "==========\n",
      "together:meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo - To compare the two numbers, we need to look at the decimal part. \n",
      "\n",
      "9.11 has a decimal part of 0.11, and 9.9 has a decimal part of 0.9. \n",
      "\n",
      "Since 0.11 is greater than 0.9, 9.11 is bigger than 9.9.\n",
      "==========\n",
      "octo:meta-llama-3.1-8b-instruct - 9.9 is bigger than 9.11.\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "compare_llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "198b213a-b7bf-4cce-8c30-a8408454370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Which number is bigger, 9.11 or 9.9? Think step by step.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a3fb8fc-a7a2-47d3-9db2-792f03cc47c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws:meta.llama3-8b-instruct-v1:0 - Let's break it down step by step!\n",
      "\n",
      "1. Compare the whole numbers: Both numbers have the same whole number part, which is 9.\n",
      "2. Compare the decimal parts: 9.11 has a decimal part of 0.11, while 9.9 has a decimal part of 0.9.\n",
      "3. Since 0.11 is smaller than 0.9, 9.11 is smaller than 9.9.\n",
      "\n",
      "So, the correct answer is: 9.9 is bigger than 9.11.\n",
      "==========\n",
      "groq:llama3-8b-8192 - Let's break it down step by step:\n",
      "\n",
      "1. Both numbers have the same first digit, which is 9.\n",
      "2. The second digit of 9.11 is 1, and the second digit of 9.9 is 9.\n",
      "3. Since 9 is greater than 1, the second digit of 9.9 is larger than the second digit of 9.11.\n",
      "4. Therefore, 9.9 is greater than 9.11.\n",
      "\n",
      "So, the answer is: 9.9 is bigger than 9.11.\n",
      "==========\n",
      "fireworks:accounts/fireworks/models/llama-v3-8b-instruct - Let's break it down step by step!\n",
      "\n",
      "1. Compare the whole numbers: Both numbers have the same whole part, which is 9.\n",
      "2. Compare the decimal parts: 0.11 is less than 0.9.\n",
      "\n",
      "So, 9.11 is less than 9.9.\n",
      "==========\n",
      "octo:meta-llama-3-8b-instruct - Let's break it down step by step:\n",
      "\n",
      "1. Both numbers have the same first digit, which is 9.\n",
      "2. The second digit of 9.11 is 1, and the second digit of 9.9 is 9.\n",
      "3. Since 9 is greater than 1, the second digit of 9.9 is larger than the second digit of 9.11.\n",
      "4. Therefore, 9.9 is greater than 9.11.\n",
      "\n",
      "So, the answer is: 9.9 is bigger than 9.11.\n",
      "==========\n",
      "together:meta-llama/Llama-3-8b-chat-hf - Let's break it down step by step:\n",
      "\n",
      "1. Both numbers have the same first digit, which is 9.\n",
      "2. The second digit of 9.11 is 1, and the second digit of 9.9 is 9.\n",
      "3. Since 9 is greater than 1, the second digit of 9.9 is larger than the second digit of 9.11.\n",
      "4. Therefore, 9.9 is greater than 9.11.\n",
      "\n",
      "So, the answer is: 9.9 is bigger than 9.11.\n",
      "==========\n",
      "openai:gpt-3.5-turbo - To determine which number is bigger, we can compare the whole numbers first. In this case, both numbers have a whole number of 9.\n",
      "\n",
      "Next, we can compare the decimal parts. In 9.11, the decimal part is 0.11, and in 9.9, the decimal part is 0.9.\n",
      "\n",
      "Since 0.11 is greater than 0.9, we can conclude that 9.11 is bigger than 9.9.\n",
      "==========\n",
      "replicate:meta/meta-llama-3-8b-instruct - Let's break it down step by step!\n",
      "\n",
      "1. Both numbers start with the same digits: 9.1\n",
      "2. The next digit is also the same: 1\n",
      "3. The last digit is different: 9.11 has a 1, while 9.9 has a 9\n",
      "\n",
      "Since 9 is greater than 1, the correct answer is:\n",
      "\n",
      "9.9 is bigger than 9.11\n",
      "==========\n",
      "aws:meta.llama3-1-8b-instruct-v1:0 - Let's compare the two numbers step by step.\n",
      "\n",
      "1. Both numbers start with 9, so we can ignore the 9 for now.\n",
      "2. We're left with 0.11 and 0.9. Which one is bigger?\n",
      "3. Since 0.9 is bigger than 0.11, the whole number 9.9 is bigger than 9.11.\n",
      "\n",
      "So, the answer is: 9.9 is bigger than 9.11.\n",
      "==========\n",
      "groq:llama-3.1-8b-instant - Let's compare the two numbers step by step:\n",
      "\n",
      "1. Both numbers start with 9, so we can ignore the 9 for now.\n",
      "2. We're left with 0.11 and 0.9.\n",
      "3. 0.9 is bigger than 0.11.\n",
      "4. Since 9 is the same in both numbers, the overall number with 0.9 is bigger than the number with 0.11.\n",
      "\n",
      "Therefore, 9.9 is bigger than 9.11.\n",
      "==========\n",
      "fireworks:accounts/fireworks/models/llama-v3p1-8b-instruct - Let's compare the two numbers step by step.\n",
      "\n",
      "1. Both numbers have the same whole number part, which is 9.\n",
      "2. Now, let's look at the decimal part. 9.11 has a decimal part of 0.11, while 9.9 has a decimal part of 0.9.\n",
      "3. Since 0.11 is greater than 0.9, the number 9.11 is greater than 9.9.\n",
      "\n",
      "So, the answer is: 9.11 is bigger.\n",
      "==========\n",
      "together:meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo - To determine which number is bigger, let's break it down step by step:\n",
      "\n",
      "1. Both numbers start with 9, so we can ignore the 9 for now.\n",
      "2. We're left with 0.11 and 0.9.\n",
      "3. 0.9 is greater than 0.11 because 9 is greater than 11 when comparing the same number of decimal places.\n",
      "4. Since 0.9 is greater than 0.11, and both numbers start with 9, the original number 9.9 is greater than 9.11.\n",
      "\n",
      "Therefore, 9.9 is the bigger number.\n",
      "==========\n",
      "octo:meta-llama-3.1-8b-instruct - Let's compare the two numbers step by step:\n",
      "\n",
      "1. Both numbers start with 9, so we can ignore the 9 for now.\n",
      "2. We're left with 0.11 and 0.9.\n",
      "3. 0.9 is bigger than 0.11 because 9 is bigger than 11.\n",
      "4. Since 0.9 is bigger than 0.11, and both numbers started with 9, 9.9 is bigger than 9.11.\n",
      "\n",
      "So, the answer is: 9.9 is bigger than 9.11.\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "compare_llm(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66987d26-4245-4de1-816f-fa57475101f3",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "1. Not all LLMs are created equal - not even all Llama 3 (or 3.1) are created equal (by different providers).\n",
    "2. Ask LLM to think step by step may help improve its reasoning.\n",
    "3. The way LLM was trained and tokenized could lead it to some weird reasoning.\n",
    "4. A more comprehensive benchmark would be desired, but a quick LLM comparison like shown here can be the first step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
